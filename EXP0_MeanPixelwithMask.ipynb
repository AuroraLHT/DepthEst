{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.column_data import *\n",
    "# from fastai.conv_learner import *\n",
    "# from fastai.dataset import *\n",
    "from fastai.torch_imports import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Acyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPCODE = \"oldfasion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -f KITTI/ | grep .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = pd.read_csv('./KITTI/training_192_640_pre.csv'), pd.read_csv('./KITTI/validation_192_640_pre.csv')\n",
    "train, val = shuffle(train), shuffle(val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn0, trn1, trn2, trn_camera = train.t0, train.t1,train.t2, train[['fx', 'fy', 'cx', 'cy']]\n",
    "val0, val1, val2, val_camera  = val.t0, val.t1, val.t2, val[['fx', 'fy', 'cx', 'cy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_camera.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = f\n",
    "bs = 8\n",
    "PATH = 'Fastai_TRN'\n",
    "DPATH = \"KITTI/\"\n",
    "verbose = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn0, trn1, trn2, trn_camera = train.t0, train.t1,train.t2, train[['fx', 'fy', 'cx', 'cy']]\n",
    "val0, val1, val2, val_camera  = val.t0, val.t1, val.t2, val[['fx', 'fy', 'cx', 'cy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = imagenet_stats\n",
    "tfm_norm = Normalize(*stats, tfm_y=TfmType.NO) \n",
    "tfm_denorm = Denormalize(*stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tfms = UnScaleTransforms(sz=None, tfms=[], normalizer=tfm_norm, denorm=tfm_denorm, tfm_y=TfmType.NO, sz_y=None)\n",
    "val_tfms = UnScaleTransforms(sz=None, tfms=[], normalizer=tfm_norm, denorm=tfm_denorm, tfm_y=TfmType.NO, sz_y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = (trn_tfms, val_tfms)\n",
    "\n",
    "MD1 = get_MD(trn0, val0, tfms, bs, DPATH, PATH)\n",
    "MD2 = get_MD(trn1, val1, tfms, bs, DPATH, PATH)\n",
    "MD3 = get_MD(trn2, val2, tfms, bs, DPATH, PATH)\n",
    "MDcam = get_cam(trn_camera, val_camera, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgnet_mean, imgnet_std = torch.from_numpy(stats[0]).float(), torch.from_numpy(stats[1]).float()\n",
    "imgnet_mean, imgnet_std = imgnet_mean.view(1,3,1,1), imgnet_std.view(1,3,1,1)\n",
    "denorm = denormer(imgnet_mean, imgnet_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(m, opt, MD1, MD2, MD3, MDcam, denorm):\n",
    "    collector = LossCollect(6)\n",
    "    \n",
    "    m.train()\n",
    "    DL1, DL2, DL3, DLcam = iter(MD1.trn_dl), iter(MD2.trn_dl), iter(MD3.trn_dl), iter(MDcam.trn_dl)\n",
    "    losses = []  \n",
    "    \n",
    "    #for i in range(2): # just for testing\n",
    "    for i in range(len(MD1.trn_ds)//bs-len(losses)):\n",
    "        t1 = time.time()\n",
    "        opt.zero_grad()\n",
    "        imgs1, imgs2, imgs3, cam = V([next(DL1), next(DL2),next(DL3), next(DLcam)[1]])\n",
    "        \n",
    "        d1, d2, d3, trans, rotation, = m(imgs1, imgs2, imgs3)\n",
    "        #pdb.set_trace()\n",
    "        imgs1, imgs2, imgs3 = denorm(imgs1), denorm(imgs2), denorm(imgs3) \n",
    "        #pdb.set_trace()\n",
    "        loss, details = l(d1, d2, d3, trans, rotation, imgs1, imgs2, imgs3, cam)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        t2 = time.time()\n",
    "        \n",
    "        collector.collect(\n",
    "            loss.data[0],\n",
    "            details[0].data[0],\n",
    "            details[1].data[0],\n",
    "            details[2].data[0],\n",
    "            details[3].data[0],\n",
    "            t2-t1\n",
    "            )\n",
    "        \n",
    "        # total appr smooth ssim l1\n",
    "        if i%verbose == 0: print(\"{:.4f}, {:.4f}, {:.4E}, {:.4f}, {:.4f}, {:.2f}s/batch\".format(*collector.show()))\n",
    "    return collector.collections[0]  #return the total losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(m, MD1, MD2, MD3, MDcam, folder):\n",
    "    \n",
    "    DL1, DL2, DL3, DLcam = iter(MD1.val_dl), iter(MD2.val_dl), iter(MD3.val_dl), iter(MDcam.val_dl)\n",
    "    m.eval()\n",
    "    for i in range(3): \n",
    "        imgs1, imgs2, imgs3, cam = V([next(DL1), next(DL2),next(DL3), next(DLcam)[1]], volatile=True)\n",
    "        d1s, d2s, d3s, trans, rotation, = m(imgs1, imgs2, imgs3)\n",
    "        #pdb.set_trace()\n",
    "        imgs1, imgs2, imgs3 = denorm(imgs1, volatile=True), denorm(imgs2, volatile=True), denorm(imgs3, volatile=True) \n",
    "        #pdb.set_trace()\n",
    "        d2 = d2s[0]\n",
    "        # d2 = F.upsample(input=d2, scale_factor=2**di, mode='bilinear')\n",
    "        cx12, cy12, dm12 = l.appr.offset.forward(trans=trans[:,0], rotation=rotation[:,0], inv_depth = d2, camera = cam)\n",
    "        #pdb.set_trace()\n",
    "\n",
    "        x12, ivm12 = l.appr.sampler.forward(imgs1, cx12, cy12)\n",
    "        ivm12.volatile = True\n",
    "\n",
    "        del dm12 \n",
    "        del ivm12\n",
    "        \n",
    "        imgs2 = tonp(imgs2.permute(0,2,3,1))\n",
    "        x12 = tonp(x12.permute(0,2,3,1))\n",
    "        d2 = tonp(d2)\n",
    "        \n",
    "        for j in range(bs):\n",
    "            save_res(imgs2[j], x12[j], d2[j][0], folder/\"{}{}.png\".format(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, m, opt, MD1, MD2, MD3, MDcam):\n",
    "    for i in range(epoch):\n",
    "        print(\"--------------------epoch {} start:----------------------\".format(i))\n",
    "        losses = train(m, opt, MD1, MD2, MD3, MDcam)\n",
    "        losses= [ str(loss) for loss in losses ]\n",
    "        folder = Path(\"./tmp\")\n",
    "        folder.mkdir(exist_ok=True)\n",
    "        file = folder / 'epoch{}.log'.format(i)\n",
    "        with file.open('w') as f:\n",
    "            f.write(\"\\n\".join(losses))\n",
    "        save_model(m, str(folder / \"epoch{}.M\".format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expfolder = Path('./experiment/') / EXPCODE\n",
    "expfolder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one use mean pixel loss with old fasion in view mask to filter out the unavalible pixels.\n",
    "m = TriDepth(get_base(f, cut), 1, setting=[False, False, False], is_per_pixel_min=False, is_mask=True).cuda()\n",
    "l = Loss(smooth_scale=0.001, appr_scale=0.85, warp_setting=[True, True, True, True]).cuda()\n",
    "opt = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr =1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 8\n",
    "#     set_trainable(m.depth.rn, False)\n",
    "for i in range(epoch):    \n",
    "    thisfolder = expfolder/\"epoch_{}\".format(i+1)\n",
    "    thisfolder.mkdir(exist_ok=True)\n",
    "\n",
    "    print(\"------------------training model-----------------\")\n",
    "    losses = train(m, opt, MD1, MD2, MD3, MDcam, denorm)\n",
    "    print(\"------------------saving model-------------------\")\n",
    "    save_model(m, thisfolder/\"model.M\")\n",
    "    print(\"------------------writting log-------------------\")\n",
    "    logger = thisfolder/\"log\"\n",
    "    losses = [ str(loss) for loss in losses]\n",
    "    with logger.open('w') as f: f.write(\"\\n\".join(losses))\n",
    "    print(\"---------------------predicting------------------\")    \n",
    "    predictfolder = thisfolder/'predicts'\n",
    "    predictfolder.mkdir(exist_ok=True)\n",
    "    evaluate(m, MD1, MD2, MD3, MDcam, predictfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL1, DL2, DL3, DLcam = iter(MD1.val_dl), iter(MD2.val_dl), iter(MD3.val_dl), iter(MDcam.val_dl)\n",
    "m.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs1, imgs2, imgs3, cam = V([next(DL1), next(DL2),next(DL3), next(DLcam)[1]], volatile=True)\n",
    "d1s, d2s, d3s, trans, rotation, = m(imgs1, imgs2, imgs3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2s[0].min(), d2s[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
