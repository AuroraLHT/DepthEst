{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "# from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -f KITTI/ | grep .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls KITTI/2011_10_03/2011_10_03_drive_0034_sync/image_03/data/0000003783.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, val= pd.read_csv('./KITTI/training.csv'), pd.read_csv('./KITTI/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val= pd.read_csv('./KITTI/training_192_640_pre.csv'), pd.read_csv('./KITTI/validation_192_640_pre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(3):\n",
    "    train = train.sample(frac=1)\n",
    "    \n",
    "\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    val = val.sample(frac=1)\n",
    "\n",
    "val.reset_index(drop=True, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn0, trn1, trn2, trn_camera = train.t0, train.t1,train.t2, train[['fx', 'fy', 'cx', 'cy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val0, val1, val2, val_camera  = val.t0, val.t1, val.t2, val[['fx', 'fy', 'cx', 'cy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_camera.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_idxs = get_cv_idxs(len(fnames), val_pct=min(0.01/keep_pct, 0.1))\n",
    "((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(fnames), np.array(fnames))\n",
    "len(val_x),len(trn_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_tfms = [\n",
    "    #RandomDihedral(tfm_y=TfmType.NO),\n",
    "    RandomLighting(b=0.05, c=0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = f\n",
    "scale,bs = 1, 4\n",
    "#scale,bs = 4, 32\n",
    "sz = None #np.array([345, 1242]) \n",
    "sz_y = None \n",
    "\n",
    "PATH = 'Fastai_TRN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, y, transform, path):\n",
    "        super().__init__(fnames, transform, path)\n",
    "    def get_y(self, i): return None\n",
    "    def get_c(self): return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnShuffleImageData(ImageData):\n",
    "    def __init__(self, path, datasets, bs, num_workers, classes):\n",
    "        trn_ds,val_ds,fix_ds,aug_ds,test_ds,test_aug_ds = datasets\n",
    "        self.path,self.bs,self.num_workers,self.classes = path,bs,num_workers,classes\n",
    "        self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl,self.test_dl,self.test_aug_dl = [\n",
    "            self.get_dl(ds,shuf) for ds,shuf in [\n",
    "                (trn_ds,False),(val_ds,False),(fix_ds,False),(aug_ds,False),\n",
    "                (test_ds,False),(test_aug_ds,False)\n",
    "            ]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnScaleTransforms():\n",
    "    def __init__(self, sz, tfms, normalizer, denorm,\n",
    "                 tfm_y=TfmType.NO, sz_y=None):\n",
    "        if sz_y is None: sz_y = sz\n",
    "        self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n",
    "        self.tfms = tfms\n",
    "        if normalizer is not None: self.tfms.append(normalizer)\n",
    "        self.tfms.append(ChannelOrder(tfm_y))\n",
    "\n",
    "    def __call__(self, im, y=None): return compose(im, y, self.tfms)\n",
    "    def __repr__(self): return str(self.tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a little modification which remove the multipler at the batch size of the val DL\n",
    "class UnDBSColumnarModelData(ModelData):\n",
    "    def __init__(self, path, trn_ds, val_ds, bs, test_ds=None, shuffle=True):\n",
    "        test_dl = DataLoader(test_ds, bs, shuffle=False, num_workers=1) if test_ds is not None else None\n",
    "        super().__init__(path, DataLoader(trn_ds, bs, shuffle=shuffle, num_workers=1),\n",
    "            DataLoader(val_ds, bs, shuffle=False, num_workers=1), test_dl)\n",
    "\n",
    "    @classmethod\n",
    "    def from_arrays(cls, path, val_idxs, xs, y, is_reg=True, is_multi=False, bs=64, test_xs=None, shuffle=True):\n",
    "        ((val_xs, trn_xs), (val_y, trn_y)) = split_by_idx(val_idxs, xs, y)\n",
    "        test_ds = PassthruDataset(*(test_xs.T), [0] * len(test_xs), is_reg=is_reg, is_multi=is_multi) if test_xs is not None else None\n",
    "        return cls(path, PassthruDataset(*(trn_xs.T), trn_y, is_reg=is_reg, is_multi=is_multi),\n",
    "                   PassthruDataset(*(val_xs.T), val_y, is_reg=is_reg, is_multi=is_multi),\n",
    "                   bs=bs, shuffle=shuffle, test_ds=test_ds)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frames(cls, path, trn_df, val_df, trn_y, val_y, cat_flds, bs=64, is_reg=True, is_multi=False, test_df=None, shuffle=True):\n",
    "        trn_ds  = ColumnarDataset.from_data_frame(trn_df,  cat_flds, trn_y, is_reg, is_multi)\n",
    "        val_ds  = ColumnarDataset.from_data_frame(val_df,  cat_flds, val_y, is_reg, is_multi)\n",
    "        test_ds = ColumnarDataset.from_data_frame(test_df, cat_flds, None,  is_reg, is_multi) if test_df is not None else None\n",
    "        return cls(path, trn_ds, val_ds, bs, test_ds=test_ds, shuffle=shuffle)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frame(cls, path, val_idxs, df, y, cat_flds, bs=64, is_reg=True, is_multi=False, test_df=None, shuffle=True):\n",
    "        ((val_df, trn_df), (val_y, trn_y)) = split_by_idx(val_idxs, df, y)\n",
    "        return cls.from_data_frames(path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, is_multi, test_df=test_df, shuffle=shuffle)\n",
    "\n",
    "    def get_learner(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n",
    "                    y_range=None, use_bn=False, **kwargs):\n",
    "        model = MixedInputModel(emb_szs, n_cont, emb_drop, out_sz, szs, drops, y_range, use_bn, self.is_reg, self.is_multi)\n",
    "        return StructuredLearner(self, StructuredModel(to_gpu(model)), opt_fn=optim.Adam, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Transforms():\n",
    "    def __init__(self, sz, tfms, normalizer, denorm, crop_type=CropType.CENTER,\n",
    "                 tfm_y=TfmType.NO, sz_y=None):\n",
    "        if sz_y is None: sz_y = sz\n",
    "        self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n",
    "        crop_tfm = crop_fn_lu[crop_type](sz, tfm_y, sz_y)\n",
    "        self.tfms = tfms\n",
    "        self.tfms.append(crop_tfm)\n",
    "        if normalizer is not None: self.tfms.append(normalizer)\n",
    "        self.tfms.append(ChannelOrder(tfm_y))\n",
    "\n",
    "    def __call__(self, im, y=None): return compose(im, y, self.tfms)\n",
    "    def __repr__(self): return str(self.tfms)\n",
    "    \n",
    "\n",
    "def image_gen(normalizer, denorm, sz, tfms=None, max_zoom=None, pad=0, crop_type=None,\n",
    "              tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, scale=None):\n",
    "    \"\"\"\n",
    "    Generate a standard set of transformations\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "     normalizer :\n",
    "         image normalizing function\n",
    "     denorm :\n",
    "         image denormalizing function\n",
    "     sz :\n",
    "         size, sz_y = sz if not specified.\n",
    "     tfms :\n",
    "         iterable collection of transformation functions\n",
    "     max_zoom : float,\n",
    "         maximum zoom\n",
    "     pad : int,\n",
    "         padding on top, left, right and bottom\n",
    "     crop_type :\n",
    "         crop type\n",
    "     tfm_y :\n",
    "         y axis specific transformations\n",
    "     sz_y :\n",
    "         y size, height\n",
    "     pad_mode :\n",
    "         cv2 padding style: repeat, reflect, etc.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "     type : ``Transforms``\n",
    "         transformer for specified image operations.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "     Transforms: the transformer object returned by this function\n",
    "    \"\"\"\n",
    "    if tfm_y is None: tfm_y=TfmType.NO\n",
    "    if tfms is None: tfms=[]\n",
    "    elif not isinstance(tfms, collections.Iterable): tfms=[tfms]\n",
    "    if sz_y is None: sz_y = sz\n",
    "    if scale is None:\n",
    "        scale = [RandomScale(sz, max_zoom, tfm_y=tfm_y, sz_y=sz_y) if max_zoom is not None\n",
    "                 else Scale(sz, tfm_y, sz_y=sz_y)]\n",
    "    elif not is_listy(scale): scale = [scale]\n",
    "    if pad: scale.append(AddPadding(pad, mode=pad_mode))\n",
    "    if crop_type!=CropType.GOOGLENET: tfms=scale+tfms\n",
    "    return Transforms(sz, tfms, normalizer, denorm, crop_type,\n",
    "                      tfm_y=tfm_y, sz_y=sz_y)\n",
    "\n",
    "def noop(x):\n",
    "    \"\"\"dummy function for do-nothing.\n",
    "    equivalent to: lambda x: x\"\"\"\n",
    "    return x\n",
    "\n",
    "transforms_basic    = [RandomRotate(10), RandomLighting(0.05, 0.05)]\n",
    "transforms_side_on  = transforms_basic + [RandomFlip()]\n",
    "transforms_top_down = transforms_basic + [RandomDihedral()]\n",
    "\n",
    "imagenet_stats = A([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\"\"\"Statistics pertaining to image data from image net. mean and std of the images of each color channel\"\"\"\n",
    "inception_stats = A([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "inception_models = (inception_4, inceptionresnet_2)\n",
    "\n",
    "def tfms_from_stats(stats, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n",
    "                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n",
    "    \"\"\" Given the statistics of the training image sets, returns separate training and validation transform functions\n",
    "    \"\"\"\n",
    "    if aug_tfms is None: aug_tfms=[]\n",
    "    tfm_norm = Normalize(*stats, tfm_y=tfm_y if norm_y else TfmType.NO) if stats is not None else None\n",
    "    tfm_denorm = Denormalize(*stats) if stats is not None else None\n",
    "    val_crop = CropType.CENTER if crop_type in (CropType.RANDOM,CropType.GOOGLENET) else crop_type\n",
    "    val_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=val_crop,\n",
    "            tfm_y=tfm_y, sz_y=sz_y, scale=scale)\n",
    "    trn_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=crop_type,\n",
    "            tfm_y=tfm_y, sz_y=sz_y, tfms=aug_tfms, max_zoom=max_zoom, pad_mode=pad_mode, scale=scale)\n",
    "    return trn_tfm, val_tfm\n",
    "\n",
    "\n",
    "def tfms_from_model(f_model, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n",
    "                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n",
    "    \"\"\" Returns separate transformers of images for training and validation.\n",
    "    Transformers are constructed according to the image statistics given by the model. (See tfms_from_stats)\n",
    "\n",
    "    Arguments:\n",
    "        f_model: model, pretrained or not pretrained\n",
    "    \"\"\"\n",
    "    stats = inception_stats if f_model in inception_models else imagenet_stats\n",
    "    return tfms_from_stats(stats, sz, aug_tfms, max_zoom=max_zoom, pad=pad, crop_type=crop_type,\n",
    "                           tfm_y=tfm_y, sz_y=sz_y, pad_mode=pad_mode, norm_y=norm_y, scale=scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    return Transforms(sz, tfms, normalizer, denorm, crop_type,\n",
    "                      tfm_y=tfm_y, sz_y=sz_y, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = imagenet_stats\n",
    "tfm_norm = Normalize(*stats, tfm_y=TfmType.NO) \n",
    "tfm_denorm = Denormalize(*stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tfms = UnScaleTransforms(sz=None, tfms=[], normalizer=tfm_norm, denorm=tfm_denorm, tfm_y=TfmType.NO, sz_y=sz_y)\n",
    "val_tfms = UnScaleTransforms(sz=None, tfms=[], normalizer=tfm_norm, denorm=tfm_denorm, tfm_y=TfmType.NO, sz_y=sz_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgnet_mean, imgnet_std = torch.from_numpy(stats[0]).float(), torch.from_numpy(stats[1]).float()\n",
    "imgnet_mean, imgnet_std = imgnet_mean.view(1,3,1,1), imgnet_std.view(1,3,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(imgs, mean, std):\n",
    "    return V(imgs.cpu().data * std + mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MD(trn, val):\n",
    "    \n",
    "#     tfms = tfms_from_model(\n",
    "#         arch,\n",
    "#         sz,\n",
    "#         crop_type=CropType.NO,\n",
    "#         tfm_y=TfmType.NO,\n",
    "#         aug_tfms=aug_tfms,\n",
    "#         sz_y=sz_y)\n",
    "\n",
    "    tfms = (trn_tfms, val_tfms)\n",
    "    \n",
    "    datasets = ImageData.get_ds(\n",
    "        UnsupFilesDataset,\n",
    "        (trn, None),\n",
    "        (val, None),\n",
    "        tfms, path='KITTI/')\n",
    "    md = UnShuffleImageData(\n",
    "        PATH,\n",
    "        datasets,\n",
    "        bs, num_workers=16,\n",
    "        classes=None)\n",
    "    \n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cam(trn_cam, val_cam):\n",
    "    return UnDBSColumnarModelData.from_data_frames(\n",
    "        path= None,\n",
    "        trn_df=trn_cam, val_df=val_cam,\n",
    "        trn_y=None, val_y=None,\n",
    "        cat_flds=[],\n",
    "        bs=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MD1 = get_MD(trn0, val0)\n",
    "MD2 = get_MD(trn1, val1)\n",
    "MD3 = get_MD(trn2, val2)\n",
    "MDcam = get_cam(trn_camera, val_camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, scale=10, Tscale=2, ndown=2):\n",
    "        super().__init__()\n",
    "        self.appr = TriAppearanceLoss(scale=Tscale) #, ndown=ndown)\n",
    "        self.smooth = SmoothLoss()\n",
    "        self.scale = scale\n",
    "    def forward(self, d1s, d2s ,d3s, trans, rotation, x1, x2, x3, camera):\n",
    "        appr_loss, details = self.appr(d2s, trans, rotation, x1, x2, x3, camera)\n",
    "        smooth_losses = [ 0.5/(i+1) * self.smooth(d2) for i, d2 in enumerate(d2s) ]\n",
    "        #smooth_losses = [ self.smooth(d1)+self.smooth(d2) + self.smooth(d3) for d1, d2, d3 in zip(d1s, d2s, d3s) ]\n",
    "        smooth_loss = torch.mean(torch.cat(smooth_losses, dim=0)) * self.scale\n",
    "        #print(type(appr_loss))\n",
    "        #print(type(smooth_loss))\n",
    "        return appr_loss + smooth_loss, (appr_loss, smooth_loss, *details) \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TriDepth(get_base(), 1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable(m.depth.rn, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Loss(scale=1, Tscale=1).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = optim.SGD(filter(lambda p: p.requires_grad, m.parameters()), lr=0.001, momentum=0.9)\n",
    "opt = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr =1e-4,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imgbatch1 = next(iter(MD1.trn_dl))\n",
    "imgbatch2 = next(iter(MD2.trn_dl))\n",
    "imgbatch3 = next(iter(MD3.trn_dl))\n",
    "cambatch = next(iter(MDcam.trn_dl))\n",
    "\n",
    "img1 = MD1.trn_ds.denorm(imgbatch1)[0]\n",
    "img2 = MD2.trn_ds.denorm(imgbatch2)[0]\n",
    "img3 = MD3.trn_ds.denorm(imgbatch3)[0]\n",
    "cam = cambatch[1][0]\n",
    "\n",
    "f, axs = plt.subplots(1, 3, figsize=(12, 6))\n",
    "axs[0].imshow(img1)\n",
    "axs[1].imshow(img2)\n",
    "axs[2].imshow(img3)\n",
    "\n",
    "print(cam.cpu().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DL1, DL2, DL3, DLcam = iter(MD1.trn_dl), iter(MD2.trn_dl), iter(MD3.trn_dl), iter(MDcam.trn_dl)\n",
    "imgs1, imgs2, imgs3, cam = V([next(DL1), next(DL2),next(DL3), next(DLcam)[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d1, d2, d3, poses_x2 = m(imgs1, imgs2, imgs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss, details = l(d1, d2, d3, poses_x2, imgs1, imgs2, imgs3, cam)\n",
    "loss.backward()\n",
    "opt.step()\n",
    "losses.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l1_loss(imgs1, imgs2, mask=V(torch.ones_like(imgs1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL1, DL2, DL3, DLcam = iter(MD1.trn_dl), iter(MD2.trn_dl), iter(MD3.trn_dl), iter(MDcam.trn_dl)\n",
    "losses = []\n",
    "verbose = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(MD1.trn_ds)//bs-len(losses)):\n",
    "    opt.zero_grad()\n",
    "    imgs1, imgs2, imgs3, cam = V([next(DL1), next(DL2),next(DL3), next(DLcam)[1]])\n",
    "    \n",
    "    d1, d2, d3, trans, rotation, = m(imgs1, imgs2, imgs3)\n",
    "    \n",
    "    imgs1, imgs2, imgs3 = denorm(imgs1, imgnet_mean, imgnet_std), denorm(imgs2, imgnet_mean, imgnet_std), denorm(imgs3, imgnet_mean, imgnet_std) \n",
    "    \n",
    "    loss, details = l(d1, d2, d3, trans, rotation, imgs1, imgs2, imgs3, cam)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    losses.append(loss.data[0])\n",
    "    # appr smooth ssim l1\n",
    "    if i%verbose == 0: print(loss.data[0],\n",
    "                             details[0].data[0],\n",
    "                             details[1].data[0],\n",
    "                             details[2].data[0],\n",
    "                             details[3].data[0],\n",
    "                             sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(m, opt, MD1, MD2, MD3, MDcam):\n",
    "    DL1, DL2, DL3, DLcam = iter(MD1.trn_dl), iter(MD2.trn_dl), iter(MD3.trn_dl), iter(MDcam.trn_dl)\n",
    "    losses = []  \n",
    "\n",
    "    for i in range(len(MD1.trn_ds)//bs-len(losses)):\n",
    "        opt.zero_grad()\n",
    "        imgs1, imgs2, imgs3, cam = V([next(DL1), next(DL2),next(DL3), next(DLcam)[1]])\n",
    "\n",
    "        d1, d2, d3, trans, rotation, = m(imgs1, imgs2, imgs3)\n",
    "\n",
    "        imgs1, imgs2, imgs3 = denorm(imgs1, imgnet_mean, imgnet_std), denorm(imgs2, imgnet_mean, imgnet_std), denorm(imgs3, imgnet_mean, imgnet_std) \n",
    "\n",
    "        loss, details = l(d1, d2, d3, trans, rotation, imgs1, imgs2, imgs3, cam)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.data[0])\n",
    "        # appr smooth ssim l1\n",
    "        if i%verbose == 0: print(loss.data[0],\n",
    "                                 details[0].data[0],\n",
    "                                 details[1].data[0],\n",
    "                                 details[2].data[0],\n",
    "                                 details[3].data[0],\n",
    "                                 sep='\\t')\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, m, opt, MD1, MD2, MD3, MDcam):\n",
    "    for i in range(epoch):\n",
    "        print(\"--------------------epoch {} start:----------------------\".format(i))\n",
    "        losses = train(m, opt, MD1, MD2, MD3, MDcam)\n",
    "        losses= [ str(loss) for loss in losses ]\n",
    "        folder = Path(\"./tmp\")\n",
    "        folder.mkdir(exist_ok=True)\n",
    "        file = folder / 'epoch{}.log'.format(i)\n",
    "        with file.open('w') as f:\n",
    "            f.write(\"\\n\".join(losses))\n",
    "        save_model(m, str(folder / \"epoch{}.M\".format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(5, m, opt, MD1, MD2, MD3, MDcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_imports import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./TriDepth.M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(m, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(m, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l *.M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verbose = 20\n",
    "def fit(model, metric, opt, MD1, MD2, MD3, MDcam):\n",
    "    DL1, DL2, DL3, DLcam = iter(MD1.trn_dl), iter(MD2.trn_dl), iter(MD3.trn_dl), iter(MDcam.trn_dl)\n",
    "    losses = []\n",
    "    for i in range(len(MD1.trn_ds)//bs):\n",
    "        opt.zero_grad()\n",
    "        imgs1, imgs2, imgs3, cam = V([next(DL1), next(DL2),next(DL3), next(DLcam)[1]])\n",
    "        \n",
    "        d1, d2, d3, poses_x2 = m(imgs1, imgs2, imgs3)\n",
    "        loss, details = l(d1, d2, d3, poses_x2, imgs1, imgs2, imgs3, cam)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.data[0])\n",
    "        if i%verbose == 0: print(loss.data[0],\n",
    "                                 details[0].data[0],\n",
    "                                 details[1].data[0],\n",
    "                                 details[2].data[0],\n",
    "                                 details[3].data[0],\n",
    "                                 sep='\\t')\n",
    "    return A(loesses).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit(m, l, opt, MD1, MD2, MD3, MDcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL1, DL2, DL3, DLcam = iter(MD1.val_dl), iter(MD2.val_dl), iter(MD3.val_dl), iter(MDcam.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs1, imgs2, imgs3, cam = V([next(DL1), next(DL2),next(DL3), next(DLcam)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1s, d2s, d3s, transistion, rotation = m(imgs1, imgs2, imgs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "d2 = d2s[i]\n",
    "#d1, d2, d3 = d1s[0], d2s[0], d3s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if i>0: d2 = F.upsample(input=d2, scale_factor=2**i, mode='bilinear')\n",
    "cx12, cy12, dm12 = l.appr.offset.forward(trans=transistion[:,0], rotation=rotation[:,0], inv_depth = d2, camera = cam)\n",
    "#cx32, cy32, dm32 = l.appr.offset.forward(trans=transistion[:,1], rotation=rotation[:,1], inv_depth = d2, camera = cam)\n",
    "\n",
    "x12, ivm12 = l.appr.sampler.forward(imgs1, cx12, cy12)\n",
    "#x32, ivm32 = l.appr.sampler.forward(imgs2, cx32, cy32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transistion.shape, rotation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transistion[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_depth(depth, index=0, figsize=(12,4), scale=50, inv=True):\n",
    "    inv_depth = depth.cpu().data[index].numpy()\n",
    "    inv_depth = np.clip(inv_depth, a_min=0.01, a_max=None)\n",
    "    if inv:\n",
    "        depth = 1/inv_depth[0]\n",
    "    else:\n",
    "        depth = inv_depth[0]\n",
    "        \n",
    "    m, std, mx = depth.mean(axis=(0, 1)), depth.std(axis=(0, 1)), depth.max(axis=(0, 1))\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(\n",
    "        depth*scale,\n",
    "        cmap=\"viridis\",\n",
    "        #vmin=max(m - 2*std, 0),\n",
    "        #vmax=min(m+2*std, mx)\n",
    "    )\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(recon, index=0, figsize=(12,4)):\n",
    "    recon = MD1.trn_ds.denorm(recon)[index]\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(recon)\n",
    "    plt.axis('off')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mask(mask, index=0, figsize=(12,4)):\n",
    "    plt.style.use('grayscale')\n",
    "    mask = mask[index]\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(mask.cpu().data.numpy(),cmap=\"gray\", vmin=0, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(imgs1, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_img(imgs2, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_img(x12, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot_img(x32, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npd2 = 1/(d2.cpu() + 0.01).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npd2.mean(), npd2.std(), npd2.min(), npd2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_depth(d2, index, scale=1, inv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask(ivm12, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask(dm12, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot_mask(ivm32, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot_mask(dm32, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs1[0].mean(), imgs1[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2[0].mean(), d2[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_loss(imgs1, imgs2, V(torch.ones_like(imgs1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_loss(imgs1, imgs2, V(torch.ones_like(imgs1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
