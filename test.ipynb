{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img = plt.imread('KITTI/'+train.t0[2])\n",
    "print(img.shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -f KITTI/ | grep .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm KITTI/training188_620.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls KITTI/2011_10_03/2011_10_03_drive_0034_sync/image_03/data/0000003783.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, y, transform, path):\n",
    "        super().__init__(fnames, transform, path)\n",
    "    def get_y(self, i): return None\n",
    "    def get_c(self): return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, val= pd.read_csv('./KITTI/training.csv'), pd.read_csv('./KITTI/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val= pd.read_csv('./KITTI/training_188_620.csv'), pd.read_csv('./KITTI/validation_188_620.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn0, trn1, trn2, trn_camera = train.t0, train.t1,train.t2, train[['fx', 'fy', 'cx', 'cy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val0, val1, val2, val_camera  = val.t0, val.t1, val.t2, val[['fx', 'fy', 'cx', 'cy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_camera.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_idxs = get_cv_idxs(len(fnames), val_pct=min(0.01/keep_pct, 0.1))\n",
    "((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(fnames), np.array(fnames))\n",
    "len(val_x),len(trn_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_tfms = [\n",
    "    #RandomDihedral(tfm_y=TfmType.NO),\n",
    "    RandomLighting(b=0.05, c=0.05)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = f\n",
    "scale,bs = 1, 4\n",
    "sz = None #np.array([345, 1242]) \n",
    "sz_y = None \n",
    "\n",
    "# scale,bs = 4,32\n",
    "\n",
    "PATH = 'Fastai_TRN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnShuffleImageData(ImageData):\n",
    "    def __init__(self, path, datasets, bs, num_workers, classes):\n",
    "        trn_ds,val_ds,fix_ds,aug_ds,test_ds,test_aug_ds = datasets\n",
    "        self.path,self.bs,self.num_workers,self.classes = path,bs,num_workers,classes\n",
    "        self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl,self.test_dl,self.test_aug_dl = [\n",
    "            self.get_dl(ds,shuf) for ds,shuf in [\n",
    "                (trn_ds,False),(val_ds,False),(fix_ds,False),(aug_ds,False),\n",
    "                (test_ds,False),(test_aug_ds,False)\n",
    "            ]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnScaleTransforms():\n",
    "    def __init__(self, sz, tfms, normalizer, denorm,\n",
    "                 tfm_y=TfmType.NO, sz_y=None):\n",
    "        if sz_y is None: sz_y = sz\n",
    "        self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n",
    "        self.tfms = tfms\n",
    "        if normalizer is not None: self.tfms.append(normalizer)\n",
    "        self.tfms.append(ChannelOrder(tfm_y))\n",
    "\n",
    "    def __call__(self, im, y=None): return compose(im, y, self.tfms)\n",
    "    def __repr__(self): return str(self.tfms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Transforms():\n",
    "    def __init__(self, sz, tfms, normalizer, denorm, crop_type=CropType.CENTER,\n",
    "                 tfm_y=TfmType.NO, sz_y=None):\n",
    "        if sz_y is None: sz_y = sz\n",
    "        self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n",
    "        crop_tfm = crop_fn_lu[crop_type](sz, tfm_y, sz_y)\n",
    "        self.tfms = tfms\n",
    "        self.tfms.append(crop_tfm)\n",
    "        if normalizer is not None: self.tfms.append(normalizer)\n",
    "        self.tfms.append(ChannelOrder(tfm_y))\n",
    "\n",
    "    def __call__(self, im, y=None): return compose(im, y, self.tfms)\n",
    "    def __repr__(self): return str(self.tfms)\n",
    "    \n",
    "\n",
    "def image_gen(normalizer, denorm, sz, tfms=None, max_zoom=None, pad=0, crop_type=None,\n",
    "              tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, scale=None):\n",
    "    \"\"\"\n",
    "    Generate a standard set of transformations\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "     normalizer :\n",
    "         image normalizing function\n",
    "     denorm :\n",
    "         image denormalizing function\n",
    "     sz :\n",
    "         size, sz_y = sz if not specified.\n",
    "     tfms :\n",
    "         iterable collection of transformation functions\n",
    "     max_zoom : float,\n",
    "         maximum zoom\n",
    "     pad : int,\n",
    "         padding on top, left, right and bottom\n",
    "     crop_type :\n",
    "         crop type\n",
    "     tfm_y :\n",
    "         y axis specific transformations\n",
    "     sz_y :\n",
    "         y size, height\n",
    "     pad_mode :\n",
    "         cv2 padding style: repeat, reflect, etc.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "     type : ``Transforms``\n",
    "         transformer for specified image operations.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "     Transforms: the transformer object returned by this function\n",
    "    \"\"\"\n",
    "    if tfm_y is None: tfm_y=TfmType.NO\n",
    "    if tfms is None: tfms=[]\n",
    "    elif not isinstance(tfms, collections.Iterable): tfms=[tfms]\n",
    "    if sz_y is None: sz_y = sz\n",
    "    if scale is None:\n",
    "        scale = [RandomScale(sz, max_zoom, tfm_y=tfm_y, sz_y=sz_y) if max_zoom is not None\n",
    "                 else Scale(sz, tfm_y, sz_y=sz_y)]\n",
    "    elif not is_listy(scale): scale = [scale]\n",
    "    if pad: scale.append(AddPadding(pad, mode=pad_mode))\n",
    "    if crop_type!=CropType.GOOGLENET: tfms=scale+tfms\n",
    "    return Transforms(sz, tfms, normalizer, denorm, crop_type,\n",
    "                      tfm_y=tfm_y, sz_y=sz_y)\n",
    "\n",
    "def noop(x):\n",
    "    \"\"\"dummy function for do-nothing.\n",
    "    equivalent to: lambda x: x\"\"\"\n",
    "    return x\n",
    "\n",
    "transforms_basic    = [RandomRotate(10), RandomLighting(0.05, 0.05)]\n",
    "transforms_side_on  = transforms_basic + [RandomFlip()]\n",
    "transforms_top_down = transforms_basic + [RandomDihedral()]\n",
    "\n",
    "imagenet_stats = A([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\"\"\"Statistics pertaining to image data from image net. mean and std of the images of each color channel\"\"\"\n",
    "inception_stats = A([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "inception_models = (inception_4, inceptionresnet_2)\n",
    "\n",
    "def tfms_from_stats(stats, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n",
    "                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n",
    "    \"\"\" Given the statistics of the training image sets, returns separate training and validation transform functions\n",
    "    \"\"\"\n",
    "    if aug_tfms is None: aug_tfms=[]\n",
    "    tfm_norm = Normalize(*stats, tfm_y=tfm_y if norm_y else TfmType.NO) if stats is not None else None\n",
    "    tfm_denorm = Denormalize(*stats) if stats is not None else None\n",
    "    val_crop = CropType.CENTER if crop_type in (CropType.RANDOM,CropType.GOOGLENET) else crop_type\n",
    "    val_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=val_crop,\n",
    "            tfm_y=tfm_y, sz_y=sz_y, scale=scale)\n",
    "    trn_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=crop_type,\n",
    "            tfm_y=tfm_y, sz_y=sz_y, tfms=aug_tfms, max_zoom=max_zoom, pad_mode=pad_mode, scale=scale)\n",
    "    return trn_tfm, val_tfm\n",
    "\n",
    "\n",
    "def tfms_from_model(f_model, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n",
    "                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n",
    "    \"\"\" Returns separate transformers of images for training and validation.\n",
    "    Transformers are constructed according to the image statistics given by the model. (See tfms_from_stats)\n",
    "\n",
    "    Arguments:\n",
    "        f_model: model, pretrained or not pretrained\n",
    "    \"\"\"\n",
    "    stats = inception_stats if f_model in inception_models else imagenet_stats\n",
    "    return tfms_from_stats(stats, sz, aug_tfms, max_zoom=max_zoom, pad=pad, crop_type=crop_type,\n",
    "                           tfm_y=tfm_y, sz_y=sz_y, pad_mode=pad_mode, norm_y=norm_y, scale=scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    return Transforms(sz, tfms, normalizer, denorm, crop_type,\n",
    "                      tfm_y=tfm_y, sz_y=sz_y, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = imagenet_stats\n",
    "tfm_norm = Normalize(*stats, tfm_y=TfmType.NO) \n",
    "tfm_denorm = Denormalize(*stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tfms = UnScaleTransforms(sz=None, tfms=[], normalizer=tfm_norm, denorm=tfm_denorm, tfm_y=TfmType.NO, sz_y=sz_y)\n",
    "val_tfms = UnScaleTransforms(sz=None, tfms=[], normalizer=tfm_norm, denorm=tfm_denorm, tfm_y=TfmType.NO, sz_y=sz_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MD(trn, val):\n",
    "    \n",
    "#     tfms = tfms_from_model(\n",
    "#         arch,\n",
    "#         sz,\n",
    "#         crop_type=CropType.NO,\n",
    "#         tfm_y=TfmType.NO,\n",
    "#         aug_tfms=aug_tfms,\n",
    "#         sz_y=sz_y)\n",
    "\n",
    "    tfms = (trn_tfms, val_tfms)\n",
    "    \n",
    "    datasets = ImageData.get_ds(\n",
    "        UnsupFilesDataset,\n",
    "        (trn, None),\n",
    "        (val, None),\n",
    "        tfms, path='KITTI/')\n",
    "    md = UnShuffleImageData(\n",
    "        PATH,\n",
    "        datasets,\n",
    "        bs, num_workers=16,\n",
    "        classes=None)\n",
    "    \n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cam(trn_cam, val_cam):\n",
    "    return ColumnarModelData.from_data_frames(\n",
    "        path= None,\n",
    "        trn_df=trn_cam, val_df=val_cam,\n",
    "        trn_y=None, val_y=None,\n",
    "        cat_flds=[],\n",
    "        bs=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MD1 = get_MD(trn0, val0)\n",
    "MD2 = get_MD(trn1, val1)\n",
    "MD3 = get_MD(trn2, val2)\n",
    "MDcam = get_cam(trn_camera, val_camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, scale=0.01, Tscale=0.01):\n",
    "        super().__init__()\n",
    "        self.appr = TriAppearanceLoss()\n",
    "        self.smooth = SmoothLoss()\n",
    "        self.scale = scale\n",
    "    def forward(self, d1, d2 ,d3, poses_x2, x1, x2, x3, camera):\n",
    "        return ( self.appr(d1, d3, poses_x2, x1, x2, x3, camera)+\n",
    "                scale * (self.smooth(d1) +\n",
    "                         self.smooth(d2) +\n",
    "                         self.smooth(d1))\n",
    "               )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TriDepth(get_base(), 1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Loss().cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(m.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgbatch1 = next(iter(MD1.trn_dl))\n",
    "imgbatch2 = next(iter(MD2.trn_dl))\n",
    "imgbatch3 = next(iter(MD3.trn_dl))\n",
    "cambatch = next(iter(MDcam.trn_dl))\n",
    "\n",
    "img1 = MD1.trn_ds.denorm(imgbatch1)[0]\n",
    "img2 = MD2.trn_ds.denorm(imgbatch2)[0]\n",
    "img3 = MD3.trn_ds.denorm(imgbatch3)[0]\n",
    "cam = cambatch[1][0]\n",
    "\n",
    "f, axs = plt.subplots(1, 3, figsize=(12, 6))\n",
    "axs[0].imshow(img1)\n",
    "axs[1].imshow(img2)\n",
    "axs[2].imshow(img3)\n",
    "\n",
    "print(cam.cpu().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL1, DL2, DL3, DLcam = iter(MD1.trn_dl), iter(MD2.trn_dl), iter(MD3.trn_dl), iter(MDcam.trn_dl)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad()\n",
    "imgs1, imgs2, imgs3, cam = V([next(DL1), next(DL2),next(DL3), next(DLcam)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = 192\n",
    "d2 = 640\n",
    "imgs1, imgs2, imgs3 = V([torch.randn(2,3,d1,d2), torch.randn(2,3,d1,d2), torch.randn(2,3,d1,d2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nostop = True\n",
    "while nostop:\n",
    "    nostop = False\n",
    "    try:\n",
    "        d2 = d2 - 1\n",
    "        opt.zero_grad()\n",
    "        imgs1, imgs2, imgs3 = V([torch.randn(2,3,d1,d2), torch.randn(2,3,d1,d2), torch.randn(2,3,d1,d2)])\n",
    "        d1, d2, d3, poses_x2 = m(imgs1, imgs2, imgs3)\n",
    "    except Exception as e:\n",
    "        nostop = True\n",
    "    if d2 < 600: nostop = False\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2, d3, poses_x2 = m(imgs1, imgs2, imgs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = l(d1, d2, d3, poses_x2, imgs1, imgs2, imgs3, cam)\n",
    "loss.backward()\n",
    "opt.step()\n",
    "losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, metric, opt, MD1, MD2, MD3, MDcam):\n",
    "    DL1, DL2, DL3, DLcam = iter(MD1.trn_dl), iter(MD2.trn_dl), iter(MD3.trn_dl), iter(MDcam.trn_dl)\n",
    "    losses = []\n",
    "    for i in tqdm(range(len(MD1.trn_ds))):\n",
    "        opt.zero_grad()\n",
    "        imgs1, imgs2, imgs3, cam = V([next(DL1), next(DL2),next(DL3), next(DLcam)[1]])\n",
    "        \n",
    "        d1, d2, d3, poses_x2 = m(imgs1, imgs2, imgs3)\n",
    "        loss = l(d1, d2, d3, poses_x2, imgs1, imgs2, imgs3, cam)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss)\n",
    "    return torch.cat(loesses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, l, opt, MD1, MD2, MD3, MDcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
