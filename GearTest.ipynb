{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from models_v2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BilinearSampler Test Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesh(H, W):\n",
    "    x, y= torch.arange(W), torch.arange(H)\n",
    "    x = x.unsqueeze(0).repeat(H, 1)\n",
    "    y = y.unsqueeze(1).repeat(1, W)\n",
    "    xy = torch.stack((x/((W-1)/2)-1, y/((H-1)/2)-1 ), -1)\n",
    "    return xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pimg = plt.imread('img/donald-trump-threatens-ex-obama-officials.jpg')\n",
    "plt.imshow(pimg); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pimg = pimg[100:400, 150:450]\n",
    "plt.imshow(pimg); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timg = torch.from_numpy(pimg).type(torch.FloatTensor).permute(2,0,1)\n",
    "\n",
    "pimg[:,:,0] - timg[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creat the Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = mesh(300,300); xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simg = F.grid_sample( timg.unsqueeze(0), xy.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.abs(timg-simg.data)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(simg.squeeze(0).permute(1,2,0).data.numpy()/255 ); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funny Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy[0,0], xy[-1, -1]\n",
    "x, y = xy[:,:,0], xy[:,:,1]\n",
    "xy = torch.stack((y,x),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simg = F.grid_sample( timg.unsqueeze(0), xy.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(simg.squeeze(0).permute(1,2,0).data.numpy()/255 ); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it with all zero (just sample the middle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.zeros_like(xy.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simg = F.grid_sample( timg.unsqueeze(0), zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(simg.squeeze(0).permute(1,2,0).data.numpy()/255 ); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BilinearProj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = BilinearProj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesh2(H, W):\n",
    "    x, y= torch.arange(W), torch.arange(H)\n",
    "    x = x.unsqueeze(0).repeat(H, 1)\n",
    "    y = y.unsqueeze(1).repeat(1, W)\n",
    "    #xy = torch.stack((x/((W-1)/2)-1, y/((H-1)/2)-1 ), -1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y= mesh2(300,300)\n",
    "sampled = sampler(timg.unsqueeze(0), x.unsqueeze(0), y.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sampled.squeeze(0).permute(1,2,0).data.numpy()/255 ); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 30, 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = Offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = V(torch.zeros(1,6)) + EPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_depth = V(torch.ones(1, 1, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = V(torch.FloatTensor(np.array([372.106469,368.444783,314.357737,88.265872]))).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx, ty, dmask= offset.forward(pose, inv_depth, camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx[0,:3, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty[0,:3, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmask[0,:3, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sin(torch.FloatTensor([3.14/2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = V(torch.FloatTensor(np.array((EPS, EPS, 3.14/2, 0, 0, 0))).view(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx, ty, dmask= offset.forward(pose, inv_depth, camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty[0, :3, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx[0, :3, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Twist2Mat(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Twist2Mat, self).__init__()\n",
    "        self.register_buffer('o', torch.zeros(1,1))\n",
    "        self.register_buffer('E', torch.eye(3))\n",
    "\n",
    "    def cprodmat_batch(self, a_batch):\n",
    "        batch_size, _ = a_batch.size()\n",
    "        o = Variable(self.o).expand(batch_size, 1)\n",
    "        a0 = a_batch[:, 0:1]\n",
    "        a1 = a_batch[:, 1:2]\n",
    "        a2 = a_batch[:, 2:3]\n",
    "        return torch.cat((o, -a2, a1, a2, o, -a0, -a1, a0, o), 1).view(batch_size, 3, 3)\n",
    "\n",
    "    def forward(self, twist_batch):\n",
    "        batch_size, _ = twist_batch.size()\n",
    "        rot_angle = twist_batch.norm(p=2, dim=1).view(batch_size, 1).clamp(min=1e-5)\n",
    "        # rot_axis = twist_batch / rot_angle.expand(batch_size, 3)\n",
    "        rot_axis = twist_batch / rot_angle\n",
    "        A = self.cprodmat_batch(rot_axis)\n",
    "        return Variable(self.E).view(1, 3, 3).expand(batch_size, 3, 3)\\\n",
    "            + A*rot_angle.sin().view(batch_size, 1, 1).expand(batch_size, 3, 3)\\\n",
    "            + A.bmm(A)*((1-rot_angle.cos()).view(batch_size, 1, 1).expand(batch_size, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m = Twist2Mat().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(t2m.E) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_vec = pose[:, :3]\n",
    "offset.rot_vec2mat(rot_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = mesh2(H, W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equvalent statement! but the one below save computation\n",
    "xyz = R_batch[:, :, 0:2].bmm(xy.view(1, 2, N).expand(batch_size, 2, N))\\\n",
    "    + R_batch[:, :, 2:3].expand(batch_size, 3, N)\\\n",
    "    + t_batch.view(batch_size, 3, 1).expand(batch_size, 3, N) * inv_depth.view(-1, 1, N).expand(batch_size, 3, N)\n",
    "z = xyz[:, 2:3, :].clamp(min=1e-10)\n",
    "xy_warp = xyz[:, 0:2, :] / z.expand(batch_size, 2, N)\n",
    "# u_warp = ((xy_warp[:, 0, :]*self.camparams['fx'] + self.camparams['cx'])/2**level_idx - .5).view(batch_size, N)\n",
    "# v_warp = ((xy_warp[:, 1, :]*self.camparams['fy'] + self.camparams['cy'])/2**level_idx - .5).view(batch_size, N)\n",
    "# print(self.x_pyramid[level_idx][0])\n",
    "u_warp = ((xy_warp[:, 0, :] * self.camparams['fx'] + self.camparams['cx']) - getattr(self, 'x_'+str(level_idx))[0]).view(\n",
    "    batch_size, N) / 2 ** level_idx\n",
    "v_warp = ((xy_warp[:, 1, :] * self.camparams['fy'] + self.camparams['cy']) - getattr(self, 'y_'+str(level_idx))[0]).view()/2 ** level_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSIM loss test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pimg = plt.imread('img/donald-trump-threatens-ex-obama-officials.jpg')\n",
    "plt.imshow(pimg); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timg = torch.from_numpy(pimg).type(torch.FloatTensor).permute(2,0,1)/255.0\n",
    "timg = timg.unsqueeze(0).cuda()\n",
    "mask = torch.ones_like(timg)\n",
    "\n",
    "noise = torch.randn(timg.size()).cuda()\n",
    "timg = V(timg)\n",
    "noise = Variable(noise, requires_grad=True)\n",
    "#noise = nn.Parameter(noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_ssim\n",
    "\n",
    "verbose = 200\n",
    "count = 0\n",
    "\n",
    "# Functional: pytorch_ssim.ssim(img1, img2, window_size = 11, size_average = True)\n",
    "ssim_value = pytorch_ssim.ssim(timg, noise).data[0]\n",
    "print(\"Initial ssim:\", ssim_value)\n",
    "\n",
    "# Module: pytorch_ssim.SSIM(window_size = 11, size_average = True)\n",
    "ssim_loss = pytorch_ssim.SSIM()\n",
    "\n",
    "optimizer = optim.Adam([noise], lr=0.001)\n",
    "\n",
    "while ssim_value < 0.98:\n",
    "    count += 1\n",
    "    if count % verbose == 0:\n",
    "        print(ssim_value)\n",
    "        plt.imshow(noise.cpu().data[0].permute(1,2,0).numpy());\n",
    "        plt.show()\n",
    "    optimizer.zero_grad()\n",
    "    ssim_out = -ssim_loss(timg, noise)\n",
    "    ssim_value = - ssim_out.data[0]\n",
    "    #print(ssim_value)\n",
    "    ssim_out.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "plt.imshow(noise.cpu().data[0].permute(1,2,0).numpy());\n",
    "plt.show()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_v2 import *\n",
    "\n",
    "opt = optim.Adam([noise], lr=0.01)\n",
    "\n",
    "for i in range(3000):\n",
    "    opt.zero_grad()\n",
    "    loss = compute_SSIM( noise, timg).mean()\n",
    "\n",
    "    #loss = ssim_loss( noise, V(timg), V(mask) )\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if i % 150 == 0:\n",
    "        plt.imshow(noise.cpu().data[0].permute(1,2,0).numpy());\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_v2 import *\n",
    "\n",
    "opt = optim.Adam([noise], lr=0.01)\n",
    "\n",
    "for i in range(1000):\n",
    "    opt.zero_grad()\n",
    "    loss = l1_loss( noise, V(timg), V(mask) )\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if i % 150 == 0:\n",
    "        plt.imshow(noise.cpu().data[0].permute(1,2,0).numpy());\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Smooth Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = (torch.randn((3,256,256)) + torch.ones((3,256,256))).cuda()\n",
    "noise = noise.unsqueeze(0)\n",
    "noise = Variable(noise, requires_grad=True)\n",
    "#noise = nn.Parameter(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = SmoothLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam([noise], lr=0.1)\n",
    "\n",
    "for i in range(1000):\n",
    "    opt.zero_grad()\n",
    "    loss = l(noise)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if i % 150 == 0:\n",
    "        plt.imshow(noise.cpu().data[0].permute(1,2,0).numpy());\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap Function Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val= pd.read_csv('./KITTI/training_192_640_pre.csv'), pd.read_csv('./KITTI/validation_192_640_pre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = train.sample(1).index[0]\n",
    "img1 , img2 = train.loc[index,'t0'], train.loc[index,'t1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = torch.from_numpy( plt.imread('./KITTI/'+img1) ).permute(2,0,1).unsqueeze(0).contiguous()\n",
    "img2 =  torch.from_numpy( plt.imread('./KITTI/'+img2) ).permute(2,0,1).unsqueeze(0).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 192, 640])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = Variable( torch.randn(1,3).cuda() * 0.001, requires_grad=True )\n",
    "rot = Variable( torch.randn(1,3).cuda() * 0.01, requires_grad=True )\n",
    "\n",
    "scale = 0\n",
    "b, c, h, w = img1.size()\n",
    "depth = Variable( torch.ones(b, c, h//2**scale, w//2**scale).cuda(), requires_grad=True )\n",
    "\n",
    "#depth = Variable( torch.randn(img1.size()).cuda(), requires_grad=True )\n",
    "\n",
    "camera = V(torch.FloatTensor([370.454846,366.80941,309.62854,92.687081]).cuda().unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  1\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n",
       "  0\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth.mean(), depth.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = Offset3().cuda()\n",
    "sampler = BilinearProj().cuda()\n",
    "smooth  = SmoothLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/paperspace/DepthEst/models_v2.py(443)pixel2cam()\n",
      "-> cam_coors = cam_coors / inv_depth\n",
      "(Pdb) \n",
      "(Pdb) \n",
      "(Pdb) \n",
      "(Pdb) cam_coors.shape\n",
      "torch.Size([1, 192, 640, 3])\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-33d27435a40f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minv_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdepth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcx12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcy12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_mask12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mx12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_mask12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcy12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DepthEst/models_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, trans, rotation, inv_depth, camera)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mpixel_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_coords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m         \u001b[0mcam_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel2cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_intrinsics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mproj_tgt_cam_to_src_pixel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintrinsics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DepthEst/models_v2.py\u001b[0m in \u001b[0;36mpixel2cam\u001b[0;34m(self, inv_depth, pixel_coors, inv_intrinsics, ishomo)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# cam_coors = cam_coors * inv_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0mcam_coors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam_coors\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0minv_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mishomo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mcam_coors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam_coors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DepthEst/models_v2.py\u001b[0m in \u001b[0;36mpixel2cam\u001b[0;34m(self, inv_depth, pixel_coors, inv_intrinsics, ishomo)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# cam_coors = cam_coors * inv_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0mcam_coors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam_coors\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0minv_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mishomo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mcam_coors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam_coors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = optim.Adam([trans, rot], lr=0.01)\n",
    "opt2 = optim.Adam([depth], lr=.001)\n",
    "for i in range(5000):\n",
    "    \n",
    "    \n",
    "    opt.zero_grad()\n",
    "    opt2.zero_grad()\n",
    "\n",
    "    if scale>0:\n",
    "        updepth = F.upsample(input=depth, scale_factor=2**scale, mode='bilinear')\n",
    "    else:\n",
    "        updepth = depth    \n",
    "    \n",
    "    inv_depth = F.sigmoid(updepth) * 10 + 0.01\n",
    "    cx12, cy12, d_mask12 = offset.forward(trans, rot, inv_depth = inv_depth, camera = camera)\n",
    "    x12, in_mask12 = sampler.forward(V(img1), cx12, cy12)\n",
    "\n",
    "    #m = (d_mask12*in_mask12).unsqueeze(1)     \n",
    "    m = d_mask12.unsqueeze(1)\n",
    "    \n",
    "    #loss = .15*l1_loss( V(img2), x12, m) + .85*ssim_loss( V(img2), x12, m) #+ smooth(inv_depth) * 10\n",
    "    loss = .85*l1_loss( V(img2), x12, m) \n",
    "    #loss += .15*ssim_loss( V(img2), x12, m) \n",
    "    loss += smooth(inv_depth) * 50\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_depth.mean(), inv_depth.std(), inv_depth.min(), inv_depth.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(recon, index=0, figsize=(12,4)):\n",
    "    recon = recon[index].permute(1,2,0).numpy()\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(recon)\n",
    "    plt.axis('off')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_depth(depth, index=0, figsize=(12,4), scale=50, inv=True):\n",
    "    inv_depth = depth.cpu().data[index].numpy()\n",
    "    inv_depth = np.clip(inv_depth, a_min=0.01, a_max=None)\n",
    "    if inv:\n",
    "        depth = 1/inv_depth[0]\n",
    "    else:\n",
    "        depth = inv_depth[0]\n",
    "        \n",
    "    m, std, mx = depth.mean(axis=(0, 1)), depth.std(axis=(0, 1)), depth.max(axis=(0, 1))\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(\n",
    "        depth*scale,\n",
    "        cmap = \"gray\"\n",
    "        #cmap=\"viridis\",\n",
    "        #vmin=max(m - 2*std, 0),\n",
    "        #vmax=min(m+2*std, mx)\n",
    "    )\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mask(mask, index=0, figsize=(12,4)):\n",
    "    plt.style.use('grayscale')\n",
    "    mask = mask[index]\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(mask.cpu().data.numpy(),cmap=\"gray\", vmin=0, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_depth(inv_depth, index=0, scale=1,inv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask(d_mask12, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask(in_mask12, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(x12.cpu().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(inv_depth.cpu().data.view(-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
