{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.column_data import *\n",
    "# from fastai.conv_learner import *\n",
    "# from fastai.dataset import *\n",
    "from fastai.torch_imports import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -f KITTI/ | grep .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = pd.read_csv('./KITTI/training_192_640_pre.csv'), pd.read_csv('./KITTI/validation_192_640_pre.csv')\n",
    "train, val = shuffle(train), shuffle(val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn0, trn1, trn2, trn_camera = train.t0, train.t1,train.t2, train[['fx', 'fy', 'cx', 'cy']]\n",
    "val0, val1, val2, val_camera  = val.t0, val.t1, val.t2, val[['fx', 'fy', 'cx', 'cy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_camera.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = f\n",
    "bs = 4\n",
    "PATH = 'Fastai_TRN'\n",
    "DPATH = \"KITTI/\"\n",
    "verbose = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn0, trn1, trn2, trn_camera = train.t0, train.t1,train.t2, train[['fx', 'fy', 'cx', 'cy']]\n",
    "val0, val1, val2, val_camera  = val.t0, val.t1, val.t2, val[['fx', 'fy', 'cx', 'cy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = imagenet_stats\n",
    "tfm_norm = Normalize(*stats, tfm_y=TfmType.NO) \n",
    "tfm_denorm = Denormalize(*stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tfms = UnScaleTransforms(sz=None, tfms=[], normalizer=tfm_norm, denorm=tfm_denorm, tfm_y=TfmType.NO, sz_y=None)\n",
    "val_tfms = UnScaleTransforms(sz=None, tfms=[], normalizer=tfm_norm, denorm=tfm_denorm, tfm_y=TfmType.NO, sz_y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = (trn_tfms, val_tfms)\n",
    "\n",
    "MD1 = get_MD(trn0, val0, tfms, bs, DPATH, PATH)\n",
    "MD2 = get_MD(trn1, val1, tfms, bs, DPATH, PATH)\n",
    "MD3 = get_MD(trn2, val2, tfms, bs, DPATH, PATH)\n",
    "MDcam = get_cam(trn_camera, val_camera, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgnet_mean, imgnet_std = torch.from_numpy(stats[0]).float(), torch.from_numpy(stats[1]).float()\n",
    "imgnet_mean, imgnet_std = imgnet_mean.view(1,3,1,1), imgnet_std.view(1,3,1,1)\n",
    "denorm = denormer(imgnet_mean, imgnet_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, scale=1, Tscale=0.15):\n",
    "        super().__init__()\n",
    "        self.appr = TriAppearanceLoss(scale=Tscale) \n",
    "        self.smooth = SmoothLoss()\n",
    "        self.scale = scale\n",
    "    def forward(self, d1s, d2s ,d3s, trans, rotation, x1, x2, x3, camera):\n",
    "        appr_loss, details = self.appr(d2s, trans, rotation, x1, x2, x3, camera)\n",
    "        smooth_losses = [ 0.5/(i+1) * self.smooth(d2) for i, d2 in enumerate(d2s) ]\n",
    "        #smooth_losses = [ self.smooth(d1)+self.smooth(d2) + self.smooth(d3) for d1, d2, d3 in zip(d1s, d2s, d3s) ]\n",
    "        smooth_loss = torch.mean(torch.cat(smooth_losses, dim=0)) * self.scale\n",
    "        #print(type(appr_loss))\n",
    "        #print(type(smooth_loss))\n",
    "        return appr_loss + smooth_loss, (appr_loss, smooth_loss, *details) \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(m, opt, MD1, MD2, MD3, MDcam, denorm):\n",
    "    m.train()\n",
    "    DL1, DL2, DL3, DLcam = iter(MD1.trn_dl), iter(MD2.trn_dl), iter(MD3.trn_dl), iter(MDcam.trn_dl)\n",
    "    losses = []  \n",
    "    \n",
    "    #for i in range(2): # just for testing\n",
    "    for i in range(len(MD1.trn_ds)//bs-len(losses)):\n",
    "        opt.zero_grad()\n",
    "        imgs1, imgs2, imgs3, cam = V([next(DL1), next(DL2),next(DL3), next(DLcam)[1]])\n",
    "\n",
    "        d1, d2, d3, trans, rotation, = m(imgs1, imgs2, imgs3)\n",
    "        #pdb.set_trace()\n",
    "        imgs1, imgs2, imgs3 = denorm(imgs1), denorm(imgs2), denorm(imgs3) \n",
    "        #pdb.set_trace()\n",
    "        loss, details = l(d1, d2, d3, trans, rotation, imgs1, imgs2, imgs3, cam)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.data[0])\n",
    "        # appr smooth ssim l1\n",
    "        if i%verbose == 0: print(loss.data[0],\n",
    "                                 details[0].data[0],\n",
    "                                 details[1].data[0],\n",
    "                                 details[2].data[0],\n",
    "                                 details[3].data[0],\n",
    "                                 sep='\\t')\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(m, MD1, MD2, MD3, MDcam, folder):\n",
    "    \n",
    "    DL1, DL2, DL3, DLcam = iter(MD1.val_dl), iter(MD2.val_dl), iter(MD3.val_dl), iter(MDcam.val_dl)\n",
    "    m.eval()\n",
    "    for i in range(10): \n",
    "        imgs1, imgs2, imgs3, cam = V([next(DL1), next(DL2),next(DL3), next(DLcam)[1]])\n",
    "        d1s, d2s, d3s, trans, rotation, = m(imgs1, imgs2, imgs3)\n",
    "        imgs1, imgs2, imgs3 = denorm(imgs1), denorm(imgs2), denorm(imgs3) \n",
    "       \n",
    "        i = 0\n",
    "        d2 = d2s[i]\n",
    "        if i>0: d2 = F.upsample(input=d2, scale_factor=2**i, mode='bilinear')\n",
    "        cx12, cy12, dm12 = l.appr.offset.forward(trans=trans[:,0], rotation=rotation[:,0], inv_depth = d2, camera = cam)\n",
    "        x12, ivm12 = l.appr.sampler.forward(imgs1, cx12, cy12)\n",
    "        \n",
    "        imgs2 = tonp(imgs2.permute(0,2,3,1))\n",
    "        x12 = tonp(x12.permute(0,2,3,1))\n",
    "        d2 = tonp(d2)\n",
    "        \n",
    "        for j in range(bs):\n",
    "            save_res(imgs2[i], x12[i], d2[i][0], folder/\"{}{}.png\".format(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, m, opt, MD1, MD2, MD3, MDcam):\n",
    "    for i in range(epoch):\n",
    "        print(\"--------------------epoch {} start:----------------------\".format(i))\n",
    "        losses = train(m, opt, MD1, MD2, MD3, MDcam)\n",
    "        losses= [ str(loss) for loss in losses ]\n",
    "        folder = Path(\"./tmp\")\n",
    "        folder.mkdir(exist_ok=True)\n",
    "        file = folder / 'epoch{}.log'.format(i)\n",
    "        with file.open('w') as f:\n",
    "            f.write(\"\\n\".join(losses))\n",
    "        save_model(m, str(folder / \"epoch{}.M\".format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS = [0, 1, 0.15, 0.3, 0.5, 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expfolder = Path('./experiment/loss/')\n",
    "expfolder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts in TS:\n",
    "    thisfolder = expfolder / \"tscale_{}\".format(ts)\n",
    "    thisfolder.mkdir(exist_ok=True)\n",
    "    \n",
    "    m = TriDepth(get_base(), 1).cuda()\n",
    "    set_trainable(m.depth.rn, False)\n",
    "    l = Loss(scale=1, Tscale=ts).cuda()\n",
    "    opt = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr =1e-4)\n",
    "    print(\"training model\")\n",
    "    losses = train(m, opt, MD1, MD2, MD3, MDcam, denorm)\n",
    "    print(\"saving model\")\n",
    "    save_model(m, thisfolder/\"model.M\".format(ts))\n",
    "    print(\"writting log\")\n",
    "    logger = thisfolder/\"log\"\n",
    "    losses = [ str(loss) for loss in losses]\n",
    "    with logger.open('w') as f: f.write(\"\\n\".join(losses))\n",
    "    print(\"predicting\")    \n",
    "    predictfolder = thisfolder/'predicts'\n",
    "    predictfolder.mkdir(exist_ok=True)\n",
    "    evaluate(m, MD1, MD2, MD3, MDcam, predictfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TriDepth(get_base(), 1).cuda()\n",
    "set_trainable(m.depth.rn, False)\n",
    "l = Loss(scale=1, Tscale=0.15).cuda()\n",
    "opt = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr =1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL1, DL2, DL3, DLcam = iter(MD1.trn_dl), iter(MD2.trn_dl), iter(MD3.trn_dl), iter(MDcam.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs1, imgs2, imgs3, cam = V([next(DL1), next(DL2),next(DL3), next(DLcam)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2, d3, trans, rotation, = m(imgs1, imgs2, imgs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs1, imgs2, imgs3 = denorm(imgs1), denorm(imgs2), denorm(imgs3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, details = l(d1, d2, d3, trans, rotation, imgs1, imgs2, imgs3, cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses.append(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appr smooth ssim l1\n",
    "if i%verbose == 0: print(loss.data[0],\n",
    "                         details[0].data[0],\n",
    "                         details[1].data[0],\n",
    "                         details[2].data[0],\n",
    "                         details[3].data[0],\n",
    "                         sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
